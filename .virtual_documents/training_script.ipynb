import numpy as np 
import pandas as pd 
from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, LassoCV
from sklearn.metrics import f1_score, roc_auc_score, brier_score_loss
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer, SimpleImputer
from sklearn.decomposition import PCA
import scipy
from scipy.stats import kstest, ttest_ind, ks_2samp, mannwhitneyu, mode
import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')


import pandas as pd
import numpy as np
np.random.seed(42)
import warnings
import matplotlib.pyplot as plt
import scipy
from sklearn.metrics import f1_score, roc_auc_score
import lightgbm as lgb, xgboost as xgb, catboost as cb
from gc import collect
import os
import umap
from matplotlib.ticker import MaxNLocator
import seaborn as sns
from sklearn.svm import SVC, LinearSVC
from sklearn.base import clone
from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split
from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.decomposition import PCA
from sklearn.multioutput import MultiOutputClassifier
from sklearn.preprocessing import StandardScaler, FunctionTransformer, PolynomialFeatures, MinMaxScaler
from sklearn.kernel_approximation import Nystroem
from sklearn.compose import ColumnTransformer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import SimpleImputer, IterativeImputer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import f1_score, roc_curve, make_scorer
from sklearn.feature_selection import RFECV, SequentialFeatureSelector, SelectKBest
from sklearn.linear_model import LogisticRegression, RidgeClassifier,RidgeClassifierCV
from sklearn.ensemble import ExtraTreesRegressor, RandomForestClassifier, StackingClassifier
from sklearn.metrics import r2_score
from sklearn.manifold import TSNE


warnings.filterwarnings("ignore")





SEED = 42
REPEATS = 5
FOLDS = 5

train_q = pd.read_excel("Dataset/widsdatathon2025/TRAIN/TRAIN_QUANTITATIVE_METADATA.xlsx")
train_c = pd.read_excel("Dataset/widsdatathon2025/TRAIN/TRAIN_CATEGORICAL_METADATA.xlsx")
train_f = pd.read_csv("Dataset/widsdatathon2025/TRAIN/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv")


test_q = pd.read_excel("Dataset/widsdatathon2025/TEST/TEST_QUANTITATIVE_METADATA.xlsx")
test_c = pd.read_excel("Dataset/widsdatathon2025/TEST/TEST_CATEGORICAL.xlsx")
test_f = pd.read_csv("Dataset/widsdatathon2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv")


train_temp = pd.merge(train_q, train_c, on="participant_id", how="left")
train_combined = pd.merge(train_temp, train_f, on="participant_id", how="left").set_index("participant_id")

test_temp = pd.merge(test_q, test_c, on="participant_id", how="left")
test_combined = pd.merge(test_temp, test_f, on="participant_id", how="left").set_index("participant_id")

labels = pd.read_excel("Dataset/widsdatathon2025/TRAIN/TRAINING_SOLUTIONS.xlsx").set_index("participant_id")
assert all(train_combined.index == labels.index), "Label IDs don't match train IDs"


train_combined


adhd_data_train = train_combined.iloc[:, :27]
adhd_data_test = test_combined.iloc[:, :27]

sex_data_train = train_combined.iloc[:, 27:]
sex_data_test = test_combined.iloc[:, 27:]





drop_cols = [
    "Basic_Demos_Study_Site", "Basic_Demos_Study_Site", "MRI_Track_Scan_Location", "Basic_Demos_Enroll_Year", "PreInt_Demos_Fam_Child_Ethnicity",
    "PreInt_Demos_Fam_Child_Race", 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Occ'
]
adhd_data_train.drop(drop_cols, axis=1, inplace=True)
adhd_data_test.drop(drop_cols, axis=1, inplace=True)

scaler = StandardScaler()
adhd_data_train = pd.DataFrame(
    scaler.fit_transform(adhd_data_train), columns=adhd_data_train.columns, index=adhd_data_train.index
)
adhd_data_test = pd.DataFrame(
    scaler.transform(adhd_data_test), columns=adhd_data_test.columns, index=adhd_data_test.index
)

imputer = IterativeImputer(estimator=LassoCV(random_state=SEED), max_iter=5, random_state=SEED)
adhd_data_train[:] = imputer.fit_transform(adhd_data_train)
adhd_data_test[:] = imputer.transform(adhd_data_test)

y_adhd = labels["ADHD_Outcome"]
y_sex = labels["Sex_F"]
combinations = labels["ADHD_Outcome"].astype(str) + labels["Sex_F"].astype(str)


scaler = StandardScaler()
sex_data_train = pd.DataFrame(
    scaler.fit_transform(sex_data_train), columns=sex_data_train.columns, index=sex_data_train.index
)
sex_data_test = pd.DataFrame(
    scaler.transform(sex_data_test), columns=sex_data_test.columns, index=sex_data_test.index
)

imputer = SimpleImputer(strategy='median')
sex_data_train[:] = imputer.fit_transform(sex_data_train)
sex_data_test[:] = imputer.transform(sex_data_test)





def eval_metrics(y_true, y_pred, weights, label="None", thresh=0.5):
    """Evaluate predictions using Brier Score and F1 Score."""
    brier = brier_score_loss(y_true, y_pred)
    f1 = f1_score(y_true, (y_pred > thresh).astype(int), sample_weight=weights)
    print(f"{label} -> Brier Score: {brier:.4f}, F1: {f1:.4f}")
    return brier, f1

scores_sex = []
scores_adhd = []

sex_oof = np.zeros(len(y_sex))
adhd_oof = np.zeros(len(y_adhd))

t_sex = 0.3
t_adhd = 0.4

rskf = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=REPEATS, random_state=SEED)
skf = StratifiedKFold(n_splits=FOLDS)

# ----------------
# Sex_F prediction
# ----------------

for fold, (train_idx, val_idx) in enumerate(rskf.split(sex_data_train, combinations), 1):
    print(f"\n=== Fold {fold} ===")

    X_train, X_val = sex_data_train.iloc[train_idx], sex_data_train.iloc[val_idx]
    y_train_adhd, y_val_adhd = y_adhd.iloc[train_idx], y_adhd.iloc[val_idx]
    y_train_sex, y_val_sex = y_sex.iloc[train_idx], y_sex.iloc[val_idx]
    # 2x weight for Sex_F == 1 and ADHD_Outcome == 1 (as mentioned in competition evaluation)
    weights_train = np.where(combinations.iloc[train_idx]=="11", 2, 1)
    weights = np.where(combinations.iloc[val_idx]=="11", 2, 1)

    model_1 = LogisticRegressionCV(penalty="l1", Cs=10, cv=skf, fit_intercept=True, scoring="f1_micro",  max_iter=1000, random_state=SEED, solver="saga")
    model_1.fit(X_train, y_train_sex, sample_weight=weights_train)
    sex_train = model_1.predict_proba(X_train)[:, 1]
    sex_val = model_1.predict_proba(X_val)[:, 1]
    sex_oof[val_idx] += sex_val / REPEATS

    sex_brier, sex_f1 = eval_metrics(y_val_sex, sex_val, weights, "Sex_F", thresh=t_sex)
    scores_sex.append((sex_brier, sex_f1))
    
# ----------------
# Outcome_ADHD prediction
# ----------------

for fold, (train_idx, val_idx) in enumerate(rskf.split(adhd_data_train, combinations), 1):
    print(f"\n=== Fold {fold} ===")

    X_train, X_val = adhd_data_train.iloc[train_idx], adhd_data_train.iloc[val_idx]
    y_train_adhd, y_val_adhd = y_adhd.iloc[train_idx], y_adhd.iloc[val_idx]
    y_train_sex, y_val_sex = y_sex.iloc[train_idx], y_sex.iloc[val_idx]
    # 2x weight for Sex_F == 1 and ADHD_Outcome == 1 (as mentioned in competition evaluation)
    weights_train = np.where(combinations.iloc[train_idx]=="11", 2, 1)
    weights = np.where(combinations.iloc[val_idx]=="11", 2, 1)
    # X_train["sex_proba"] = sex_train
    # X_val["sex_proba"] = sex_val
    X_train["sex_proba"] = sex_oof[train_idx]
    X_val["sex_proba"] = sex_oof[val_idx]

    interactions = [
        "APQ_P_APQ_P_INV", "APQ_P_APQ_P_PP", "SDQ_SDQ_Hyperactivity", 
        "Barratt_Barratt_P2_Edu", "MRI_Track_Age_at_Scan", "SDQ_SDQ_Generating_Impact"
    ]
    for interaction in interactions:
        X_train[f"I_{interaction}"] = X_train[interaction] * X_train["sex_proba"]
        X_val[f"I_{interaction}"] = X_val[interaction] * X_val["sex_proba"]

    model_2= LogisticRegressionCV(
        penalty="l1", Cs=10, cv=skf, fit_intercept=True, scoring="f1_micro", max_iter=1000, random_state=SEED, solver="saga"
    ) 
    model_2.fit(X_train, y_train_adhd, sample_weight=weights_train)
    
    adhd_val = model_2.predict_proba(X_val)[:, 1]
    adhd_oof[val_idx] += adhd_val / REPEATS
    
    adhd_brier, adhd_f1 = eval_metrics(y_val_adhd, adhd_val, weights, "Outcome ADHD", thresh=t_adhd)
    scores_adhd.append((adhd_brier, adhd_f1))

print(f"\n=== Fold {fold} ===")
print(f"Sex Mean Brier Score: {np.mean([s[0] for s in scores_sex]):.4f}")
print(f"Sex Mean F1: {np.mean([s[1] for s in scores_sex]):.4f}")
print(f"ADHD Mean Brier Score: {np.mean([s[0] for s in scores_adhd]):.4f}")
print(f"ADHD Mean F1: {np.mean([s[1] for s in scores_adhd]):.4f}")


"""
=== Fold 1 ===
Sex_F -> Brier Score: 0.2231, F1: 0.7062

=== Fold 2 ===
Sex_F -> Brier Score: 0.2542, F1: 0.6472

=== Fold 3 ===
Sex_F -> Brier Score: 0.2177, F1: 0.6828

=== Fold 4 ===
Sex_F -> Brier Score: 0.2251, F1: 0.6725

=== Fold 5 ===
Sex_F -> Brier Score: 0.2135, F1: 0.7003

=== Fold 6 ===
Sex_F -> Brier Score: 0.2726, F1: 0.6331

=== Fold 7 ===
Sex_F -> Brier Score: 0.1993, F1: 0.6744

=== Fold 8 ===
Sex_F -> Brier Score: 0.2536, F1: 0.6838

=== Fold 9 ===
Sex_F -> Brier Score: 0.2066, F1: 0.6745

=== Fold 10 ===
Sex_F -> Brier Score: 0.2406, F1: 0.6566

=== Fold 11 ===
Sex_F -> Brier Score: 0.2217, F1: 0.6847

=== Fold 12 ===
Sex_F -> Brier Score: 0.2396, F1: 0.6494

=== Fold 13 ===
Sex_F -> Brier Score: 0.2335, F1: 0.6928

=== Fold 14 ===
Sex_F -> Brier Score: 0.2054, F1: 0.6866

=== Fold 15 ===
Sex_F -> Brier Score: 0.2200, F1: 0.6877

=== Fold 16 ===
Sex_F -> Brier Score: 0.2308, F1: 0.6744

=== Fold 17 ===
Sex_F -> Brier Score: 0.2480, F1: 0.6465

=== Fold 18 ===
Sex_F -> Brier Score: 0.2439, F1: 0.6568

=== Fold 19 ===
Sex_F -> Brier Score: 0.2302, F1: 0.6934

=== Fold 20 ===
Sex_F -> Brier Score: 0.2164, F1: 0.6831

=== Fold 21 ===
Sex_F -> Brier Score: 0.2589, F1: 0.6269

=== Fold 22 ===
Sex_F -> Brier Score: 0.2421, F1: 0.7000

=== Fold 23 ===
Sex_F -> Brier Score: 0.2125, F1: 0.6970

=== Fold 24 ===
Sex_F -> Brier Score: 0.2098, F1: 0.6749

=== Fold 25 ===
Sex_F -> Brier Score: 0.2121, F1: 0.7006

"""


"""
=== Fold 25 ===
Sex Mean Brier Score: 0.2273
Sex Mean F1: 0.6246
ADHD Mean Brier Score: 0.1437
ADHD Mean F1: 0.8839

"""





weights = ((y_adhd == 1) & (y_sex == 1)) + 1
thresholds = np.linspace(0, 1, 100)
sex_scores = []
for t in tqdm(thresholds, desc="Sex Thresholds"):
    tmp_pred = np.where(sex_oof > t, 1, 0)
    tmp_score = f1_score(y_sex, tmp_pred, sample_weight=weights)
    sex_scores.append(tmp_score)
best_sex_threshold = thresholds[np.argmax(sex_scores)]
best_sex_score = max(sex_scores)

adhd_scores = []
for t in tqdm(thresholds, desc="ADHD Thresholds"):
    tmp_pred = np.where(adhd_oof > t, 1, 0)
    tmp_score = f1_score(y_adhd, tmp_pred, sample_weight=weights)
    adhd_scores.append(tmp_score)
best_adhd_threshold = thresholds[np.argmax(adhd_scores)]
best_adhd_score = max(adhd_scores)

fig, axs = plt.subplots(2, 2, figsize=(12, 10), constrained_layout=True)

axs[0, 0].plot(thresholds, sex_scores, label='F1 Score', color='blue')
axs[0, 0].scatter(best_sex_threshold, best_sex_score, color='red', label=f'Best: {best_sex_score:.3f} (Threshold: {best_sex_threshold:.2f})')
axs[0, 0].set_title('F1 Scores vs Thresholds (Sex)')
axs[0, 0].set_xlabel('Threshold')
axs[0, 0].set_ylabel('F1 Score')
axs[0, 0].legend()

axs[0, 1].hist(sex_oof, bins=30, color='skyblue', edgecolor='black')
axs[0, 1].set_title('Distribution of sex_oof')
axs[0, 1].set_xlabel('Probability')
axs[0, 1].set_ylabel('Frequency')

axs[1, 0].plot(thresholds, adhd_scores, label='F1 Score', color='orange')
axs[1, 0].scatter(best_adhd_threshold, best_adhd_score, color='red', label=f'Best: {best_adhd_score:.3f} (Threshold: {best_adhd_threshold:.2f})')
axs[1, 0].set_title('F1 Scores vs Thresholds (ADHD)')
axs[1, 0].set_xlabel('Threshold')
axs[1, 0].set_ylabel('F1 Score')
axs[1, 0].legend()

axs[1, 1].hist(adhd_oof, bins=30, color='lightgreen', edgecolor='black')
axs[1, 1].set_title('Distribution of adhd_oof')
axs[1, 1].set_xlabel('Probability')
axs[1, 1].set_ylabel('Frequency')

plt.suptitle('Threshold Analysis and Distributions', fontsize=16)
plt.show()





model_1 = LogisticRegressionCV(penalty="l1", cv=skf, fit_intercept=True, scoring="f1", Cs=10, random_state=SEED, solver="saga")
model_1.fit(train_combined, y_sex, sample_weight=weights)

sex_proba_train = model_1.predict_proba(train_combined)[:,1]
sex_proba_test = model_1.predict_proba(test_combined)[:,1]

train_combined["sex_proba"] = sex_proba_train
test_combined["sex_proba"] = sex_proba_test

for interaction in interactions:
    train_combined[f"I_{interaction}"] = train_combined["sex_proba"] * train_combined[interaction]
    test_combined[f"I_{interaction}"] = test_combined["sex_proba"] * test_combined[interaction]

model_2 = LogisticRegressionCV(penalty="l1", cv=skf, fit_intercept=True, scoring="f1", Cs=10, random_state=SEED, solver="saga")
model_2.fit(train_combined, y_adhd, sample_weight=weights)

adhd_proba_test = model_2.predict_proba(test_combined)[:,1]
coeffs_2 = pd.DataFrame({"feature": train_combined.columns, "coeff": model_2.coef_[0]})
coeffs_2.sort_values(by="coeff", key=abs, ascending=False)[:10]





fig, ax = plt.subplots(1, 2, figsize=(12, 5))

ax[0].hist(sex_proba_test, bins=10, alpha=0.5, color='blue', label='Sex Test')
ax[0].hist(sex_oof, bins=10, alpha=0.5, color='orange', label='Sex OOF')
ax[0].set_title('Sex Predictions Distribution')
ax[0].set_xlabel('Predicted Probability')
ax[0].set_ylabel('Frequency')
ax[0].legend()

ax[1].hist(adhd_proba_test, bins=10, alpha=0.5, color='green', label='ADHD Test')
ax[1].hist(adhd_oof, bins=10, alpha=0.5, color='red', label='ADHD OOF')
ax[1].set_title('ADHD Predictions Distribution')
ax[1].set_xlabel('Predicted Probability')
ax[1].set_ylabel('Frequency')
ax[1].legend()

plt.tight_layout()
plt.show()

sex_test_result = ks_2samp(sex_proba_test, sex_oof)
adhd_test_result = ks_2samp(adhd_proba_test, adhd_oof)
sex_mwu_result = mannwhitneyu(sex_proba_test, sex_oof)
adhd_mwu_result = mannwhitneyu(adhd_proba_test, adhd_oof)

print("Kolmogorov-Smirnov Test and MannWhitneyU Results:")
print(f"Sex Test vs. OOF: Statistic={sex_test_result.statistic:.4f}, p-value={sex_test_result.pvalue:.4f}")
print(f"Sex MWU vs. OOF: Statistic={sex_mwu_result.statistic:.4f}, p-value={sex_mwu_result.pvalue:.4f}")
print(f"ADHD Test vs. OOF: Statistic={adhd_test_result.statistic:.4f}, p-value={adhd_test_result.pvalue:.4f}")
print(f"ADHD MWU vs. OOF: Statistic={adhd_mwu_result.statistic:.4f}, p-value={adhd_mwu_result.pvalue:.4f}")

submission = pd.read_excel("Dataset/widsdatathon2025/SAMPLE_SUBMISSION.xlsx")
submission["ADHD_Outcome"] = np.where(adhd_proba_test > best_adhd_threshold, 1, 0)
submission["Sex_F"] = np.where(sex_proba_test > best_sex_threshold, 1, 0)
print(f"Share ADHD OOF: {np.mean(np.where(adhd_oof > best_adhd_threshold, 1, 0))} - Share ADHD Test: {submission.ADHD_Outcome.mean()}")
print(f"Share Sex_F OOF: {np.mean(np.where(sex_oof > best_sex_threshold, 1, 0))} - Share Sex_F Test: {submission.Sex_F.mean()}")


submission.to_csv("saved_models/submission_v12.csv", index=False)



