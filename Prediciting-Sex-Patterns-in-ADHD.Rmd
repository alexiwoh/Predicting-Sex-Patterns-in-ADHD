---
title: "Predicting-Sex-Patterns-in-ADHD"
author: "Alexander Iwoh and Youssef Megahed"
date: "`r Sys.Date()`"
output: html_document
---

### Notes on the correlation between features

```{r notes}
# - I think we can drop the following columns: 
# ("Basic_Demos_Study_Site", "Basic_Demos_Study_Site", "MRI_Track_Scan_Location", "Basic_Demos_Enroll_Year")

# - Regarding SDQ: There is correlation between SDQ Scores and ADHD 
# (especially 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Difficulties_Total', 
# 'SDQ_SDQ_Externalizing', and 'SDQ_SDQ_Hyperactivity'), but not with the Sex type (no relation). 
# Also, average and IQR values for people with no ADHD are lower.

# - Regarding APQ: Some of them are right-skewed, so we can apply a log transformation before normalizing. 
# It doesn't seem to have a strong correlation between the APQ scores and ADHD. Also, 
# APQ doesn't seem to be correlated with the Sex type.

# - Regarding Other Clinical Measures: No significant differences or associations were found in this data with Sex type or ADHD.

# - Regarding Demographic Features: Most participants are in Staten Island. The most dominant ethnicity is "not Latino". 
# The majority race is White. The first parents mostly have college or graduate degrees, 
# the second parent is mixed. Their occupation is mixed as well, but with a clear minority in 5-20 level jobs.

# - Brain connectivity is basically the correlation between the metrics 
# (they represent the correlation between two brain regions).
```

### Install required packages

```{r setup packages, echo = TRUE, message = FALSE, warning = FALSE, eval = interactive()}
knitr::opts_chunk$set(
	error = TRUE,
	message = FALSE,
	warning = FALSE
) 

# Install required packages
install.packages(c(
  "dplyr",        # Data manipulation
  "tidyr",        # Data tidying and reshaping
  
  "lubridate",    # Date/time processing
  "stringr",      # String manipulation
  
  "readr",        # Read CSV/text files
  "readxl",       # Read Excel files
  
  "tidymodels",   # Unified modeling framework
  "caret",        # Model training and evaluation
  "parsnip",      # Modeling interface
  "glmnet",       # Regularized regression
  "MASS",         # Statistical modeling (stepwise selection)
  "lightgbm",     # LightGBM: Gradient boosting
  "xgboost",      # XGBoost: Extreme gradient boosting
  "Matrix",       # Sparse and dense matrix operations
  
  "recipes",      # Feature engineering
  "rsample",      # Data resampling
  
  "ggplot2",      # Data visualization
  "ggthemes",     # Additional ggplot2 themes
  "ggpubr",       # Publication-ready plots
  "gridExtra",    # Arrange multiple ggplots
  "scales",       # Axis scaling in ggplots
  "RColorBrewer", # Color palettes for ggplots
  "corrplot",     # Correlation matrix visualization
  "factoextra",   # PCA and clustering visualization
  
  "stats"         # Base R statistical functions
))

```

### Load necessary libraries

```{r setup libraries, echo = TRUE, message = FALSE, warning = FALSE}

# Data Manipulation & Handling
library(dplyr)         # Data wrangling and manipulation
library(tidyr)         # Data tidying and reshaping
library(data.table)    # Fast data manipulation with data.tables

# Date & String Processing
library(lubridate)     # Working with dates and times
library(stringr)       # String manipulation

# Data Import
library(readr)         # Reading CSV and text files
library(readxl)        # Reading Excel files

# Statistical Modeling & Machine Learning
library(tidymodels)    # Unified modeling framework
library(caret)         # Model training and evaluation
library(parsnip)       # Unified interface for modeling
library(glmnet)        # Regularized regression (Lasso & Ridge)
library(MASS)          # Stepwise selection using AIC
library(lightgbm)      # LightGBM: Gradient boosting framework
library(xgboost)       # XGBoost: Extreme gradient boosting
library(Matrix)        # Efficient sparse and dense matrix operations

# Feature Engineering & Preprocessing
library(recipes)       # Feature engineering pipeline
library(rsample)       # Data resampling (train/test splits, cross-validation)

# Visualization
library(ggplot2)       # Data visualization
library(ggthemes)      # Additional themes for ggplot2
library(ggpubr)        # Publication-ready plots
library(gridExtra)     # Arranging multiple ggplots in a grid
library(scales)        # Scaling axes and labels in ggplots
library(RColorBrewer)  # Color palettes for visualizations
library(corrplot)      # Visualization of correlation matrices
library(factoextra)    # PCA and clustering visualization

# General Statistical Functions
library(stats)         # Base R statistical functions

# Suppress warnings
options(warn=-1)
```

### Target Variables

1. **Target Variables**
   - ADHD diagnosis status (`ADHD_Outcome`)
   - Biological sex (`Sex_F`)

### Feature Variables

2. **Brain Connectivity Data**
   - fMRI connectome matrices (~19,900 features)
   - Brain region correlation values

3. **Psychological Assessment Scores**
   - Strength and Difficulties Questionnaire (SDQ) - 9 scores
   - Measures of emotional problems, behavioral issues, hyperactivity, peer problems

4. **Parenting Measures**
   - Alabama Parenting Questionnaire (APQ) - 6 scores
   - Parental discipline, involvement, monitoring styles

5. **Clinical Measures**
   - Handedness (Edinburgh Handedness Questionnaire)
   - Color vision ability

6. **Demographic Information**
   - Enrollment year
   - Study site location
   - Child's ethnicity and race
   - Parent's education level
   
# Questionnaire Features

### Strength and Difficulties Questionnaire (SDQ)

| Feature | Format | Range | Example | Description |
|---------|--------|-------|---------|-------------|
| **SDQ_SDQ_Conduct_Problems** | Integer | 0-10 | 3 | Measures behavior issues like fighting, lying, disobedience. A score of 3 indicates moderate behavioral problems. |
| **SDQ_SDQ_Difficulties_Total** | Integer | 0-40 | 17 | Overall score combining all problem areas. A score of 17 would indicate moderate overall difficulties. |
| **SDQ_SDQ_Emotional_Problems** | Integer | 0-10 | 4 | Measures anxiety, worry, sadness. A score of 4 indicates some emotional challenges. |
| **SDQ_SDQ_Externalizing** | Integer | 0-20 | 12 | Combines conduct problems and hyperactivity scores. A score of 12 suggests significant "acting out" behaviors. |
| **SDQ_SDQ_Generating_Impact** | Integer | 0-10 | 5 | Measures how problems affect daily life. A score of 5 means these issues moderately impact the child’s functioning. |
| **SDQ_SDQ_Hyperactivity** | Integer | 0-10 | 8 | Measures restlessness, concentration issues, impulsivity. A score of 8 indicates high levels of hyperactive behavior. |
| **SDQ_SDQ_Internalizing** | Integer | 0-20 | 7 | Combines emotional and peer problems. A score of 7 indicates moderate internal struggles. |
| **SDQ_SDQ_Peer_Problems** | Integer | 0-10 | 3 | Measures friendship difficulties. A score of 3 suggests some challenges with peer relationships. |
| **SDQ_SDQ_Prosocial** | Integer | 0-10 | 7 | Measures positive social behaviors. A score of 7 indicates good prosocial skills. |

### Alabama Parenting Questionnaire (APQ)

| Feature | Format | Range | Example | Description |
|---------|--------|-------|---------|-------------|
| **APQ_P_APQ_P_CP** | Integer | 0-12 | 4 | Corporal Punishment Score. A score of 4 indicates moderate use of physical discipline. |
| **APQ_P_APQ_P_ID** | Integer | 0-28 | 13 | Inconsistent Discipline Score. A score of 13 suggests moderately inconsistent rule enforcement. |
| **APQ_P_APQ_P_INV** | Integer | 0-50 | 40 | Involvement Score. A score of 40 indicates high parental engagement. |
| **APQ_P_APQ_P_OPD** | Integer | 0-28 | 18 | Other Discipline Practices Score. A score of 18 indicates moderate use of alternative discipline approaches. |
| **APQ_P_APQ_P_PM** | Integer | 0-37 | 16 | Poor Monitoring/Supervision Score. A score of 16 suggests moderate lack of parental oversight. |
| **APQ_P_APQ_P_PP** | Integer | 0-30 | 25 | Positive Parenting Score. A score of 25 indicates strong use of positive reinforcement. |

## Other Clinical Measures

| Feature | Format | Range | Example | Description |
|---------|--------|-------|---------|-------------|
| **EHQ_EHQ_Total** | Float | -100 to +100 | 76.67 | Edinburgh Handedness score. A score of 76.67 indicates strong right-handedness. |
| **ColorVision_CV_Score** | Integer | 0-14 | 14 | Color vision test score. A perfect score of 14 indicates normal color vision. |

## Demographic Features

| Feature | Format | Range | Example | Description |
|---------|--------|-------|---------|-------------|
| **Basic_Demos_Enroll_Year** | Integer | (Study years) | 2019 | Year participant joined the study. |
| **Basic_Demos_Study_Site** | Categorical integer | Site-specific codes | 2 | Location code where the participant was tested. |
| **PreInt_Demos_Fam_Child_Ethnicity** | Categorical integer | Ethnicity codes | 0 | The child’s ethnic background (e.g., 0 = Not Hispanic or Latino). |
| **PreInt_Demos_Fam_Child_Race** | Categorical integer | Race codes | 1 | The child’s racial background (e.g., 1 = White). |
| **Barratt_Barratt_P1_Edu** | Categorical integer | Education codes | 5 | Parent’s education level (e.g., 5 = Bachelor’s degree). |

## Brain Connectivity Data (Connectome Features)

| Feature | Format | Range | Example | Description |
|---------|--------|-------|---------|-------------|
| **0throw_1stcolumn** | Float | -1 to +1 | 0.327 | Correlation between brain regions 0 and 1. A value of 0.327 indicates moderate positive correlation. |
| **5throw_8thcolumn** | Float | -1 to +1 | -0.156 | Correlation between brain regions 5 and 8. A value of -0.156 indicates weak negative correlation. |
| **12throw_19thcolumn** | Float | -1 to +1 | 0.082 | Correlation between brain regions 12 and 19. A value of 0.082 indicates very weak positive correlation. |
| **64throw_80thcolumn** | Float | -1 to +1 | 0.511 | Correlation between brain regions 64 and 80. A value of 0.511 indicates strong positive correlation. |
| **98throw_112thcolumn** | Float | -1 to +1 | -0.372 | Correlation between brain regions 98 and 112. A value of -0.372 indicates moderate negative correlation. |

## Data Patterns and Interpretation

### SDQ Score Interpretation Examples:
- A child with `SDQ_SDQ_Hyperactivity = 8`, `SDQ_SDQ_Conduct_Problems = 5` likely shows significant ADHD symptoms.
- A child with `SDQ_SDQ_Emotional_Problems = 7`, `SDQ_SDQ_Peer_Problems = 6` might be experiencing anxiety and social isolation.

### Connectome Interpretation Examples:
- Strong positive correlation (0.7) between frontal and parietal regions might indicate good executive function.
- Negative correlation (-0.4) between amygdala and prefrontal regions could indicate emotional regulation difficulties.

### Parenting and ADHD Connection:
- High `APQ_P_APQ_P_ID (20)` combined with high `SDQ_SDQ_Hyperactivity (9)` might suggest inconsistent discipline contributing to ADHD symptoms.
- High `APQ_P_APQ_P_PP (27)` might be associated with better behavioral outcomes even in children with ADHD.

```{r data_classifications, message=FALSE, warning=FALSE}
numerical_columns <- list(
  "EHQ_EHQ_Total",
  "ColorVision_CV_Score",
  "APQ_P_APQ_P_CP",
  "APQ_P_APQ_P_ID",
  "APQ_P_APQ_P_INV",
  "APQ_P_APQ_P_OPD",
  "APQ_P_APQ_P_PM",
  "APQ_P_APQ_P_PP",
  "SDQ_SDQ_Conduct_Problems",
  "SDQ_SDQ_Difficulties_Total",
  "SDQ_SDQ_Emotional_Problems",
  "SDQ_SDQ_Externalizing",
  "SDQ_SDQ_Generating_Impact",
  "SDQ_SDQ_Hyperactivity",
  "SDQ_SDQ_Internalizing",
  "SDQ_SDQ_Peer_Problems",
  "SDQ_SDQ_Prosocial",
  "MRI_Track_Age_at_Scan"
)

categorical_columns <- list(
  "Basic_Demos_Enroll_Year",
  "Basic_Demos_Study_Site",
  "PreInt_Demos_Fam_Child_Ethnicity",
  "PreInt_Demos_Fam_Child_Race",
  "MRI_Track_Scan_Location",
  "Barratt_Barratt_P1_Edu",
  "Barratt_Barratt_P1_Occ",
  "Barratt_Barratt_P2_Edu",
  "Barratt_Barratt_P2_Occ"
)
```

# Load all the data from the input files

Training Dataset : Merge the quantitative, categorical metadata files & solution data

```{r data_import, message=FALSE, warning=FALSE}

print_title <- function(title) {
  cat("\n", title, "\n", strrep("=", nchar(title)), "\n")
}

# Load fMRI Functional Connectome Matrices
print_title("FUNCTIONAL CONNECTOME MATRICES DATA")
fMRI_data <- read_csv("TRAIN/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv") |> as.data.frame()

# Load Quantitative Data
print_title("QUANTITATIVE DATA")
quantitative_data <- read_excel("TRAIN/TRAIN_QUANTITATIVE_METADATA.xlsx")
summary(quantitative_data)
glimpse(quantitative_data)

# Load Categorical Data
print_title("CATEGORICAL DATA")
categorical_data <- read_excel("TRAIN/TRAIN_CATEGORICAL_METADATA.xlsx")
categorical_data[] <- lapply(categorical_data, as.factor) # Convert categorical columns to factors
summary(categorical_data)
glimpse(categorical_data)

# Load Target Data
print_title("TARGETS DATA")
targets_data <- read_excel("TRAIN/TRAINING_SOLUTIONS.xlsx")
targets_data[] <- lapply(targets_data, as.factor) # Convert categorical columns to factors
summary(targets_data)
glimpse(targets_data)

# Merge all datasets
print_title("MERGING DATASETS")
train_data <- quantitative_data |>
  left_join(categorical_data, by = "participant_id") |>
  left_join(fMRI_data, by = "participant_id") |>
  left_join(targets_data, by = "participant_id")
train_data[train_data == "NA"] <- NA  # Convert character "NA" to actual NA
train_data_original <- data.frame(train_data)

# Load Test Data (no target values)
print_title("LOADING TEST DATA")
fMRI_test <- read_csv("TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv") |> as.data.frame()
quantitative_test <- read_excel("TEST/TEST_QUANTITATIVE_METADATA.xlsx")
categorical_test <- read_excel("TEST/TEST_CATEGORICAL_METADATA.xlsx")
categorical_test[] <- lapply(categorical_test, as.factor)

test_data <- quantitative_test |>
  left_join(categorical_test, by = "participant_id") |>
  left_join(fMRI_test, by = "participant_id")
test_data[test_data == "NA"] <- NA  # Convert character "NA" to actual NA
test_data_original <- data.frame(test_data)

# Extract Feature Groups
print_title("DEFINING FEATURE GROUPS")

targets <- c("ADHD_Outcome", "Sex_F")

non_connectome_features <- colnames(train_data)[!grepl("^[0-9]", colnames(train_data)) & !(colnames(train_data) %in% targets)]

connectome_features <- colnames(train_data)[grepl("^[0-9]", colnames(train_data))]

cat("Non-Connectome Features: ", length(non_connectome_features), "\n")
cat("Connectome Features: ", length(connectome_features), "\n")

```

## BASIC DESCRIPTIVE STATISTICS

### TRAINING DATASET

```{r train_summary}
cat("Number of rows: ", nrow(train_data), "\n")
cat("Number of columns: ", ncol(train_data), "\n")
```

### TESTING DATASET

```{r test_summary}
cat("Number of rows: ", nrow(test_data), "\n")
cat("Number of columns: ", ncol(test_data), "\n")
```

### DATASET OVERVIEW

```{r dataset_overview}
cat("\nDataset Overview:\n")
cat("Training data: ", nrow(train_data), " participants, ", ncol(train_data), " features\n")
cat("Test data: ", nrow(test_data), " participants, ", ncol(test_data), " features\n")
cat("Number of non-connectome features: ", length(non_connectome_features), "\n")
cat("Number of brain connectivity features: ", length(connectome_features), "\n")
```

### Dropping Unnecessary Columns

```{r drop_columns}
drop_cols <- c("Basic_Demos_Study_Site", "Basic_Demos_Study_Site", "MRI_Track_Scan_Location", "Basic_Demos_Enroll_Year")
train_data <- train_data[, !(colnames(train_data) %in% drop_cols)]
```

```{r train_data_head}
head(train_data)
```

## HANDLING MISSING VALUES

```{r missing_values, message=FALSE, warning=FALSE}
# Check for missing values in the training data
missing_values <- colSums(is.na(train_data))

# Debugging: Print missing value counts
cat("\nTotal missing values per column:\n")
print(missing_values[missing_values > 0])

# Compute percentage of missing values
missing_percent <- 100 * missing_values / nrow(train_data)

# Create a dataframe for missing value counts
missing_df <- data.frame(
  Feature = names(missing_values),
  Missing_Values = missing_values,
  Percentage = missing_percent
)

# Filter and sort features with missing values
missing_features <- subset(missing_df, Missing_Values > 0)

if (nrow(missing_features) > 0) {
  missing_features <- missing_features[order(missing_features$Percentage, decreasing = TRUE), ]
  cat("\nFeatures with missing values in training data:\n")
  print(missing_features)
} else {
  cat("\nNo missing values found in training data!\n")
}
```

## IMPUTING MISSING VALUES FOR TRAINING DATA

```{r impute_train_missing_values, message=FALSE, warning=FALSE}

# Ensure missing values exist (including empty strings for categorical)
train_missing_values <- colSums(is.na(train_data) | train_data == "", na.rm = TRUE)
columns_with_missing_train <- names(train_missing_values)[train_missing_values > 0]
cat("Number of columns with missing values in training data:", length(columns_with_missing_train), "\n")

# Filter predefined numerical and categorical columns with missing values
numerical_cols_train <- intersect(columns_with_missing_train, unlist(numerical_columns))
categorical_cols_train <- intersect(columns_with_missing_train, unlist(categorical_columns))

# Print detected columns for imputation
cat("\nNumerical columns detected for imputation in training data:\n")
print(numerical_cols_train)

cat("\nCategorical columns detected for imputation in training data:\n")
print(categorical_cols_train)

# Impute numerical columns using median
for (col in numerical_cols_train) {
  if (sum(is.na(train_data[[col]])) > 0) {
    median_value <- median(train_data[[col]], na.rm = TRUE)
    if (!is.na(median_value)) {  # Ensure median isn't NA before replacing
      train_data[[col]][is.na(train_data[[col]])] <- median_value
    }
  }
}

# Impute categorical columns using the most frequent value (mode)
for (col in categorical_cols_train) {
  if (sum(is.na(train_data[[col]]) | train_data[[col]] == "") > 0) {  # Check for both NA and empty strings
    mode_value <- names(which.max(table(train_data[[col]][train_data[[col]] != ""], useNA = "no")))  # Ignore empty strings
    if (!is.null(mode_value)) {  # Ensure mode isn't NULL before replacing
      train_data[[col]][is.na(train_data[[col]]) | train_data[[col]] == ""] <- mode_value
    }
  }
}

# Verify missing values after imputation
train_missing_after <- sum(is.na(train_data) | train_data == "")
cat("\nMissing values after imputation in training data:", train_missing_after, "\n")

if (train_missing_after == 0) {
  cat("\nAll missing values in training data have been replaced successfully!\n")
} else {
  cat("\nWARNING: Some missing values remain in training data!\n")
}


```

## IMPUTING MISSING VALUES FOR TEST DATA

```{r impute_test_missing_values, message=FALSE, warning=FALSE}
# Ensure missing values exist (including empty strings for categorical)
test_missing_values <- colSums(is.na(test_data) | test_data == "", na.rm = TRUE)
columns_with_missing_test <- names(test_missing_values)[test_missing_values > 0]
cat("Number of columns with missing values in test data:", length(columns_with_missing_test), "\n")

# Filter predefined numerical and categorical columns with missing values
numerical_cols_test <- intersect(columns_with_missing_test, unlist(numerical_columns))
categorical_cols_test <- intersect(columns_with_missing_test, unlist(categorical_columns))

# Print detected columns for imputation
cat("\nNumerical columns detected for imputation in test data:\n")
print(numerical_cols_test)

cat("\nCategorical columns detected for imputation in test data:\n")
print(categorical_cols_test)

# Impute numerical columns using median
for (col in numerical_cols_test) {
  if (sum(is.na(test_data[[col]])) > 0) {
    median_value <- median(test_data[[col]], na.rm = TRUE)
    if (!is.na(median_value)) {  # Ensure median isn't NA before replacing
      test_data[[col]][is.na(test_data[[col]])] <- median_value
    }
  }
}

# Impute categorical columns using the most frequent value (mode)
for (col in categorical_cols_test) {
  if (sum(is.na(test_data[[col]]) | test_data[[col]] == "") > 0) {  # Check for both NA and empty strings
    mode_value <- names(which.max(table(test_data[[col]][test_data[[col]] != ""], useNA = "no")))  # Ignore empty strings
    if (!is.null(mode_value)) {  # Ensure mode isn't NULL before replacing
      test_data[[col]][is.na(test_data[[col]]) | test_data[[col]] == ""] <- mode_value
    }
  }
}

# Verify missing values after imputation
test_missing_after <- sum(is.na(test_data) | test_data == "")
cat("\nMissing values after imputation in test data:", test_missing_after, "\n")

if (test_missing_after == 0) {
  cat("\nAll missing values in test data have been replaced successfully!\n")
} else {
  cat("\nWARNING: Some missing values remain in test data!\n")
}
```


